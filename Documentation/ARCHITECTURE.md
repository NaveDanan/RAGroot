# System Architecture

Comprehensive overview of the 2025 release of the GenAI RAG application, including the latest retrieval, LaTeX, and image-generation upgrades.

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Docker Image                           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                 FastAPI Application (main.py)               â”‚  â”‚
â”‚  â”‚  â€¢ Lifecycle + dependency wiring                            â”‚  â”‚
â”‚  â”‚  â€¢ Health, stats, /answer, /stream endpoints                â”‚  â”‚
â”‚  â”‚  â€¢ Global config + hash-based index caching                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Configuration Layer        â”‚      â”‚  Evaluation & Tooling  â”‚  â”‚
â”‚  â”‚  (config.py, .env)          â”‚      â”‚  (evaluate_rag.py,     â”‚  â”‚
â”‚  â”‚  â€¢ Validation               â”‚      â”‚   setup_* scripts)      â”‚  â”‚
â”‚  â”‚  â€¢ Secrets masking          â”‚      â”‚  â€¢ Quality scoring      â”‚  â”‚
â”‚  â”‚  â€¢ Runtime overrides        â”‚      â”‚  â€¢ Regression checks    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                 â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Vector Indexer            â”‚â—„â”€â”€â”€â”€â–ºâ”‚   RAG Pipeline         â”‚  â”‚
â”‚  â”‚   (indexer.py)              â”‚      â”‚   (retriever.py)        â”‚  â”‚
â”‚  â”‚   â€¢ JSONL streaming         â”‚      â”‚   â€¢ LaTeX-aware prompts â”‚  â”‚
â”‚  â”‚   â€¢ all-mpnet-base-v2       â”‚      â”‚   â€¢ Phi-3 Mini (GGUF)   â”‚  â”‚
â”‚  â”‚     embeddings (768-dim)    â”‚      â”‚   â€¢ Strict anti-halluc. â”‚  â”‚
â”‚  â”‚   â€¢ FAISS + semantic rerank â”‚      â”‚   â€¢ SSE streaming       â”‚  â”‚
â”‚  â”‚   â€¢ LaTeX preprocessing     â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚               â”‚
â”‚                 â”‚                                 â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   LaTeX Processing          â”‚      â”‚   Image Generation     â”‚  â”‚
â”‚  â”‚   (latex_utils.py)          â”‚      â”‚   (image_gen.py)       â”‚  â”‚
â”‚  â”‚   â€¢ Inline/display parsing  â”‚      â”‚   â€¢ Provider strategy   â”‚  â”‚
â”‚  â”‚   â€¢ Symbol expansion        â”‚      â”‚   â€¢ Pollinations (free) â”‚  â”‚
â”‚  â”‚   â€¢ Dual track (search/UI)  â”‚      â”‚   â€¢ Local SD 3.5 /      â”‚  â”‚
â”‚  â”‚                             â”‚      â”‚     SDXL / Qwen         â”‚  â”‚
â”‚  â”‚                             â”‚      â”‚     SDXL / Qwen         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â€¢ Async base64 URLs   â”‚  â”‚
â”‚                 â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚               â”‚
â”‚  â”‚ Persistence & Assets        â”‚                  â”‚               â”‚
â”‚  â”‚  â€¢ index/ (FAISS + hash)    â”‚                  â”‚               â”‚
â”‚  â”‚  â€¢ models/ (GGUF + SD)      â”‚                  â”‚               â”‚
â”‚  â”‚  â€¢ static/ (UI, images)     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                  â”‚
â”‚                   Web UI (static/index.html)                     â”‚
â”‚                   â€¢ MathJax rendering                            â”‚
â”‚                   â€¢ SSE stream listener                          â”‚
â”‚                   â€¢ Image previews + stats                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Component Deep Dive

### FastAPI Service (`main.py`)
- Boots configuration, indexer, and retrieval pipeline once per container (singleton pattern).
- Exposes `/answer`, `/stream`, `/health`, `/stats`, and `/image/providers` endpoints with structured JSON.
- Performs dataset hash checks on startup to reuse cached FAISS indices, falling back to a full rebuild when source data changes.
- Surfaces runtime diagnostics (documents indexed, embedding dimension, image provider readiness) through the statistics API and logs.

### Configuration Layer (`config.py` + `.env` + setup scripts)
- Central authority for every tunable parameter with Pydantic validation, range checks, and path verification.
- Masks sensitive values (API keys, HF tokens) when printing or logging configuration.
- Ships automation helpers: `setup.ps1`, `setup_improvements.ps1`, and `setup_local_image_gen.ps1` for one-command environment preparation.
- Key defaults after the 2025 improvements:
  - `EMBEDDING_MODEL=all-mpnet-base-v2`
  - `IMAGE_API_PROVIDER=local` (fallbacks: `pollinations`, `openai`)
  - `IMAGE_MODEL_NAME` & `IMAGE_MODEL_PATH` support Stable Diffusion 3.5, SDXL Turbo, SDXL Base, or Qwen Lightning.

### Vector Indexer (`indexer.py`)
- Streams `.jsonl` input to avoid peak memory spikes; validates every record before ingestion.
- Uses `all-mpnet-base-v2` (768-dim) embeddings for 15â€“20% richer semantics compared to the legacy MiniLM model.
- Persists FAISS IndexFlatL2 indices, document metadata, and dataset hash to `index/` for instant warm starts.
- Implements semantic reranking: retrieve `top_k * RERANK_MULTIPLIER`, re-score with cosine similarity on â€œtitle + abstractâ€, then return the highest quality results.
- Integrates LaTeX preprocessing so expressions like `$O(n^2)$` become searchable (`O(n squared)`), while the untouched raw text remains available for presentation.

### LaTeX Engine (`latex_utils.py`)
- Detects inline `$...$` and block `$$...$$` segments, expands 60+ mathematical symbols, and rewrites superscripts/subscripts into natural language for embedding and LLM consumption.
- Maintains a dual-track representation: processed text for retrieval quality, original LaTeX for UI rendering via MathJax.
- Shared by the indexer (during ingestion and query encoding) and retriever (when crafting the LLM prompt).

### Retrieval & Generation (`retriever.py`)
- Tokenizes incoming queries, obtains embeddings, calls the indexer, and builds deterministic prompts.
- Enforces anti-hallucination guardrails: citations mandatory, no mixing of documents, structured answer template (Topic â†’ Approach â†’ Technical Details â†’ Results).
- Runs Phi-3 Mini 4K Instruct (Q4 quantized) through `llama.cpp` bindings with tuned generation parameters (`temperature=0.3`, `top_p=0.85`, `max_tokens=600`, `repeat_penalty=1.1`).
- Supports streaming via Server-Sent Events, forwarding partial generations to the UI for better perceived latency.

### Image Generation (`image_gen.py`)
- Strategy pattern that selects between:
  1. **Local providers** (Stable Diffusion 3.5 Medium, SDXL Turbo/Base, Qwen-Image Lightning) with lazy model download, CUDA/CPU detection, and aggressive VRAM optimisations.
  2. **Pollinations** (zero-config, free) for instant demos.
  3. **OpenAI DALLÂ·E** for premium quality with API-key gating.
- Returns base64 data URLs stored temporarily under `static/generated_images/` for seamless embedding in responses and the web UI.
- Includes scripts (`setup_local_image_gen.ps1`, `tools/test_image_gen.py`, `SD35_SETUP_GUIDE.md`) to validate hardware, authenticate gated models, and benchmark throughput.

### Web Experience (`static/index.html`)
- Pure HTML/CSS/JS bundle with no build process; compatible with Dockerâ€™s static file serving.
- Renders math notation via MathJax, displays streaming responses token-by-token, and toggles image generation requests.
- Pulls system statistics on load, showing document counts, embedding dimensions, and provider status.

### Quality Gateways & Tooling
- `evaluate_rag.py` benchmarks keyword coverage, citation accuracy, specificity, and lengthâ€”targeting 78/100 (Grade B) after improvements.
- Test scripts (`test_api.py`, `tools/test_image_gen.py`) provide regression checks for both the text and image pipelines.
- Documentation established for every subsystem (architecture, configuration, LaTeX, image setup, improvement log).

## ğŸ”„ Data & Request Flow

### Indexing Pipeline

1. **Dataset ingestion** â€“ stream JSONL line-by-line to keep RAM usage predictable.
2. **Validation** â€“ confirm required keys (`id`, `title`, `abstract`) and skip malformed rows.
3. **LaTeX processing** â€“ expand symbols for embedding, preserve originals for later display.
4. **Batch embedding** â€“ encode abstracts with `all-mpnet-base-v2` in configurable batch sizes.
5. **FAISS build + cache** â€“ construct IndexFlatL2, persist vectors, document metadata, and dataset hash to `index/`.

Typical performance (2.9k docs): ~3â€“4 minutes CPU indexing, peak memory <2.5â€¯GB.

### Query & Generation Pipeline

1. **Frontend submission** â€“ UI or API client posts to `/answer` with optional `generate_image` flag.
2. **Configuration check** â€“ resolves runtime parameters (threads, top_k, image provider).
3. **Query preprocessing** â€“ run through LaTeX handler, embed via `all-mpnet-base-v2`.
4. **Semantic retrieval + rerank** â€“ gather `top_k * multiplier`, rescore, keep highest quality.
5. **Prompt assembly** â€“ apply strict template, include citations, highlight constraints.
6. **LLM inference** â€“ Phi-3 Mini generates answer; SSE channel streams tokens if requested.
7. **Optional image generation** â€“ convert answer into visual prompt, call selected provider, embed base64 image URL.
8. **Response packaging** â€“ return answer, citations, context passages, latency metrics, and image metadata.

Observed latencies (CPU-only server):
- Embedding + retrieval + rerank: ~250â€¯ms
- LLM completion: 5â€“15â€¯s (temperature 0.3)
- Image generation: 5â€“12â€¯s (GPU local) to 16â€¯min (Qwen Lightning with CPU offload) depending on provider.

## âš™ï¸ Architectural Patterns & Trade-offs

- **Singletons** â€“ long-lived indexer, retriever, and image generator instances prevent redundant model loads inside the container.
- **Strategy** â€“ image providers and future retrieval policies can be swapped without touching caller logic.
- **Builder** â€“ prompt construction assembles role, instructions, context, and user query deterministically (critical for reproducible evaluations).
- **Hash-based caching** â€“ dataset SHA-256 fingerprinting avoids costly reindex operations when content is unchanged.
- **Dual-track text representation** â€“ LaTeX support differentiates between searchable and display-ready forms of the same document.

### Performance Considerations
- Upgrading to `all-mpnet-base-v2` increases embedding time by ~20â€¯ms per batch but improves retrieval precision by 15â€“20%.
- Semantic reranking adds ~150â€¯ms per query yet removes most â€œwrong top documentâ€ cases observed in earlier evaluations.
- Lowering `temperature` to 0.3 and nudging `top_p` to 0.85 prioritises factual accuracy over stylistic variety.
- Local image generation delivers offline capability but demands 10â€“15 GB disk per model and â‰¥12 GB VRAM for best results; Pollinations remains a fast fallback.

## ğŸ” Security & Reliability
- Environment-driven configuration prevents secrets from being hardcoded and keeps `.env` files out of version control.
- Request schemas constrain `top_k`, timeouts, and token budgets to guard against abuse.
- Optional Hugging Face authentication (`HF_TOKEN`) enables gated model downloads while avoiding token leakage in logs.
- Docker volume mounts expose datasets read-only and isolate generated assets inside the container.

## ğŸ“ˆ Scalability Outlook
- Current single-process design comfortably serves <100 concurrent requests; scaling paths include Gunicorn workers, horizontal pod autoscaling, or vector-database offloading (pgvector/Qdrant).
- For corpora >100k documents, consider sharded FAISS indexes or migrating to a managed vector store.
- Heavy image workloads can be separated into an async queue (RQ/Celery) or externalised to cloud inference endpoints.

## ğŸ§ª Quality Assurance
- `evaluate_rag.py` provides deterministic scoring across four metrics. The improvements playbook (`IMPROVEMENTS.md`, `IMPROVEMENTS_SUMMARY.md`) captures the before/after deltas (50 âœ 78 overall score).
- Test harnesses (`test_api.py`, `tools/test_image_gen.py`) cover REST correctness and GPU readiness.
- Documentation underpins onboarding: architecture, configuration, LaTeX, local image generation, and Stable Diffusion setup guides.

## ğŸ”® Roadmap Ideas
- Hybrid retrieval (BM25 + dense), cross-encoder reranking, and query expansion for even higher recall.
- Enhanced Phi-3 prompts with few-shot exemplars or migration to >8k-context models when hardware permits.
- UI polish: conversational chat mode, query history, export/share flows, and MathJax-enabled PDF export.
- Analytics: capture usage metrics, feedback loops, and automated evaluation dashboards.

## âœ… Key Takeaways
- Swapping to `all-mpnet-base-v2`, enforcing strict prompts, and adding reranking eliminated the hallucinations and vague answers identified in earlier reviews.
- LaTeX support now spans ingestion â†’ retrieval â†’ UI, making the system research-paper ready.
- Image generation is pluggable: free Pollinations for demos, local Stable Diffusion/Qwen for offline control, or OpenAI for premium output.
- The configuration layer, tooling scripts, and documentation collectively make the system reproducible, auditable, and production friendly.

This architecture balances quality, performance, and maintainability while remaining deployable with a single Docker command.
